----------------------- Page 1-----------------------

      A Few Useful Things to Know about Machine Learning 

                                                              Pedro Domingos 
                                          Department of Computer Science and Engineering 
                                                           University of Washington 
                                                      Seattle, WA 98195-2350, U.S.A. 
                                                     pedrod@cs.washington.edu 

ABSTRACT                                                                       correct output yt     for future examples xt  (e.g.,  whether the 
Machine learning algorithms can ﬁgure out how to perform                       spam  ﬁlter  correctly  classiﬁes  previously  unseen  emails  as 
important tasks by  generalizing from examples.            This is  of-        spam or not spam). 
ten  feasible  and  cost-eﬀective  where  manual  programming 
is  not.  As  more  data  becomes  available,        more  ambitious           2.    LEARNING = REPRESENTATION + 
problems  can  be  tackled.      As  a  result,  machine  learning  is               EVALUATION + OPTIMIZATION 
widely used in computer science and other ﬁelds.  However, 
                                                                               Suppose  you  have  an  application  that  you  think  machine 
developing successful machine learning applications requires 
a  substantial  amount  of “black  art” that  is  hard  to  ﬁnd  in            learning  might  be  good  for.     The  ﬁrst  problem  facing  you 
                                                                               is  the  bewildering  variety  of  learning  algorithms  available. 
textbooks.    This article summarizes twelve key lessons that 
                                                                               Which  one  to  use?    There  are  literally  thousands available, 
machine learning researchers and practitioners have learned. 
                                                                               and hundreds more are published each year.  The key to not 
These include pitfalls to avoid, important issues to focus on, 
                                                                               getting  lost  in  this  huge  space  is  to  realize  that  it  consists 
and answers to common questions. 
                                                                               of combinations of just three components.  The components 
                                                                               are: 
1.     INTRODUCTION 
Machine learning systems automatically learn programs from 
                                                                               Representation.  A classiﬁer must be represented in some 
data.  This is often a very attractive alternative to manually 
                                                                                      formal  language  that  the  computer  can  handle.        Con- 
constructing them, and in the last decade the use of machine 
                                                                                      versely, choosing a representation for a learner is tan- 
learning   has   spread   rapidly   throughout     computer     science 
                                                                                      tamount  to  choosing  the  set  of  classiﬁers  that  it  can 
and beyond.  Machine learning is used in Web search, spam 
                                                                                      possibly  learn.   This  set  is  called  the  hypothesis  space 
ﬁlters, recommender systems, ad placement, credit scoring, 
                                                                                      of  the  learner.  If  a  classiﬁer  is  not  in  the  hypothesis 
fraud detection, stock trading, drug design, and many other 
                                                                                      space, it cannot be learned.  A related question, which 
applications.  A recent report from the McKinsey Global In- 
                                                                                      we  will  address in  a  later  section,  is  how  to  represent 
stitute asserts that machine learning (a.k.a.  data mining or                         the input, i.e., what features to use. 
predictive analytics) will be the driver of the next big wave of 
innovation [16].  Several ﬁne textbooks are available to inter-                Evaluation.  An  evaluation  function  (also  called          objective 
ested practitioners and researchers (e.g, [17, 25]).  However,                        function  or  scoring  function) is  needed  to  distinguish 
much of the “folk knowledge” that is needed to successfully                           good classiﬁers from bad ones.  The evaluation function 
develop  machine  learning  applications  is  not  readily  avail-                    used  internally  by  the  algorithm  may  diﬀer  from  the 
able  in  them.   As  a  result,  many  machine  learning  projects                   external one that we want the classiﬁer to optimize, for 
take much longer than necessary or wind up producing less-                            ease of optimization (see below) and due to the issues 
than-ideal results.  Yet much of this folk knowledge is fairly                        discussed in the next section. 
easy to communicate.  This is the purpose of this article.                     Optimization.  Finally, we need a method to search among 
                                                                                      the  classiﬁers  in  the  language  for  the  highest-scoring 
Many  diﬀerent  types  of  machine  learning  exist,  but  for  il-                   one.  The choice of optimization technique is key to the 
lustration   purposes    I  will focus   on  the  most   mature    and                eﬃciency of the learner, and also helps determine the 
widely  used  one:    classiﬁcation.     Nevertheless,  the  issues  I                classiﬁer produced if the evaluation function has more 
will  discuss  apply  across  all  of  machine  learning.    A  classi-               than  one  optimum.      It  is  common  for  new  learners  to 
ﬁer  is  a  system  that  inputs  (typically)  a  vector  of  discrete                start out using oﬀ-the-shelf optimizers, which are later 
and/or  continuous feature  values  and  outputs  a  single  dis-                     replaced by custom-designed ones. 
crete  value,  the  class.  For  example,  a  spam  ﬁlter  classiﬁes 
email messages into “spam” or “not spam,” and its input may                    Table 1 shows common examples of each of these three com- 
be a Boolean vector x = (x         , . . . , x  , . . . , x  ),  where x = 1   ponents.    For  example,  k-nearest  neighbor  classiﬁes  a  test 
                                  1        j        d            j 

if  the j th  word  in  the  dictionary  appears  in  the  email  and          example  by  ﬁnding  the      k  most  similar  training  examples 
xj  = 0  otherwise.    A  learner inputs  a  training  set of  exam-           and predicting the majority class among them.  Hyperplane- 
ples  (x  , y ), where x   = (x    , . . . , x ) is an observed input          based methods form a linear combination of the features per 
        i   i            i      i,1        i,d 

and yi   is the corresponding output, and outputs a classiﬁer.                 class and predict the class with the highest-valued combina- 
The test of the learner is whether this classiﬁer produces the                 tion.  Decision  trees  test  one  feature  at  each  internal  node, 

----------------------- Page 2-----------------------

                                     Table  1:   The  three  components  of  learning  algorithms. 

                        Representation                        Evaluation                   Optimization 
                        Instances                             Accuracy/Error rate          Combinatorial optimization 
                            K-nearest neighbor                Precision and recall            Greedy search 
                            Support vector machines           Squared error                   Beam search 
                        Hyperplanes                           Likelihood                      Branch-and-bound 
                            Naive Bayes                       Posterior probability        Continuous optimization 
                            Logistic regression               Information gain                Unconstrained 
                        Decision trees                        K-L divergence                      Gradient descent 
                        Sets of rules                         Cost/Utility                        Conjugate gradient 
                            Propositional rules               Margin                              Quasi-Newton methods 
                            Logic programs                                                    Constrained 
                        Neural networks                                                           Linear programming 
                        Graphical models                                                          Quadratic programming 
                            Bayesian networks 
                            Conditional random ﬁelds 

with one branch for each feature value, and have class predic-                 Algorithm  1 LearnDT(TrainSet) 
tions at the leaves.  Algorithm 1 shows a bare-bones decision                  if all examples in  TrainSet have the same class y∗ then 
tree learner for Boolean domains, using information gain and                      return MakeLeaf(y∗) 
greedy search [21].  InfoGain(x  ,y) is the mutual information 
                                    j                                          if no feature x     has InfoGain(x  ,y) > 0 then 
                                                                                                 j                   j 
between  feature  x     and  the  class y .  MakeNode(x,c      ,c  )  re- 
                      j                                       0  1                y∗ ← Most frequent class in  TrainSet 
turns a node that tests feature x and has c0 as the child for                     return MakeLeaf(y∗) 
x = 0 and c1 as the child for x = 1.                                           x∗ ← argmaxx        InfoGain(x  ,y) 
                                                                                                 j              j 

                                                                               TS    ← Examples in  TrainSet with x           = 0 
                                                                                   0                                        ∗ 
Of course, not all combinations of one component from each                     TS1 ← Examples in  TrainSet with x∗ = 1 
column    of  Table   1  make   equal   sense.    For  example,     dis-       return MakeNode(x          , LearnDT( TS ), LearnDT( TS )) 
                                                                                                        ∗                  0                   1 
crete  representations     naturally   go  with   combinatorial     op- 
timization,  and  continuous  ones  with  continuous  optimiza- 
tion.   Nevertheless,  many  learners  have  both  discrete  and               Contamination  of  your  classiﬁer  by  test  data  can  occur  in 
continuous    components,      and   in fact  the   day  may    not  be        insidious ways, e.g., if you use test data to tune parameters 
far when every single possible combination has appeared in                     and  do  a  lot  of  tuning.  (Machine  learning  algorithms  have 
some learner!                                                                  lots of knobs, and success often comes from twiddling them 
                                                                               a  lot, so  this  is a  real  concern.)     Of  course,   holding   out 
Most    textbooks    are  organized    by  representation,    and   it’s       data  reduces  the  amount  available  for  training.        This  can 
easy   to overlook    the  fact  that   the  other  components      are        be  mitigated  by  doing  cross-validation:       randomly  dividing 
equally  important.      There  is  no  simple  recipe  for  choosing          your  training  data  into  (say)  ten  subsets,  holding  out  each 
each component, but the next sections touch on some of the                     one while training on the rest, testing each learned classiﬁer 
key  issues.   And,  as  we  will  see  below,  some  choices  in  a           on the examples it did not see, and averaging the results to 
machine learning project may be even more important than                       see how well the particular parameter setting does. 
the choice of learner. 
                                                                               In the early days of machine learning, the need to keep train- 
3.    IT’S GENERALIZATION THAT COUNTS                                          ing and test data separate was not widely appreciated.  This 
The  fundamental  goal  of  machine  learning  is  to  generalize              was  partly because,  if  the  learner  has  a  very  limited  repre- 
beyond  the  examples  in  the  training  set.      This  is  because,         sentation  (e.g.,  hyperplanes),  the  diﬀerence  between  train- 
no  matter  how  much  data  we  have,  it  is  very  unlikely  that           ing and test error may not be large.         But with very ﬂexible 
we  will  see  those  exact  examples  again  at  test  time.     (No-         classiﬁers (e.g., decision trees), or even with linear classiﬁers 
tice  that,  if  there  are  100,000  words  in  the  dictionary,  the         with a lot of features, strict separation is mandatory. 
spam ﬁlter described above has 2100,000 possible diﬀerent in- 
puts.)  Doing well on the training set is easy (just memorize                  Notice that generalization being the goal has an interesting 
the examples).     The most common mistake among machine                       consequence for machine learning.  Unlike in most other op- 
learning  beginners  is  to  test  on  the  training  data  and  have          timization  problems,  we  don’t  have  access  to  the  function 
the illusion of success.  If the chosen classiﬁer is then tested               we want to optimize!  We have to use training error as a sur- 
on new data, it is often no better than random guessing.  So,                  rogate for  test  error,  and this is  fraught with  danger.       How 
if you hire someone to build a classiﬁer, be sure to keep some                 to deal with it is addressed in some of the next sections.  On 
of  the  data  to  yourself  and  test  the  classiﬁer  they  give  you        the positive side, since the objective function is only a proxy 
on  it. Conversely,  if  you’ve  been  hired  to  build  a  classiﬁer,         for  the  true  goal,  we  may  not  need  to  fully  optimize  it;  in 
set some of the data aside from the beginning, and only use                    fact, a local optimum returned by simple greedy search may 
it to test your chosen classiﬁer at the very end, followed by                  be better than the global optimum. 
learning your ﬁnal classiﬁer on the whole data. 

----------------------- Page 3-----------------------

4.    DATA ALONE IS NOT ENOUGH                                                                     Low                     High 
Generalization being the goal has another major consequence:                                    Variance                Variance 
data alone is not enough, no matter how much of it you have. 
Consider learning a Boolean function of (say) 100 variables 
from  a  million  examples.     There  are  2100 − 106  examples 

whose classes you don’t know.  How do you ﬁgure out what 
those  classes  are?   In  the  absence  of  further  information,               High 
there is just no way to do this that beats ﬂipping a coin.  This                 Bias 
observation was ﬁrst made (in somewhat diﬀerent form) by 
the  philosopher  David  Hume  over  200  years  ago,  but  even 
today many mistakes in machine learning stem from failing 
to  appreciate  it. Every  learner  must  embody  some  knowl- 
edge  or  assumptions beyond  the  data  it’s  given  in  order  to 
generalize  beyond  it.    This  was  formalized  by  Wolpert  in 
his famous “no free lunch” theorems, according to which no                       Low 
learner can beat random guessing over all possible functions                     Bias 
to be learned [26]. 

This  seems  like  rather  depressing  news.    How  then  can  we 
ever hope to learn anything?  Luckily, the functions we want                  Figure  1:   Bias  and  variance  in  dart-throwing. 
to  learn  in the  real  world  are  not  drawn   uniformly    from 
the  set  of  all  mathematically  possible  functions!    In  fact, 
very  general  assumptions—like  smoothness,  similar  exam-               quirks in the data.  This problem is called  overﬁtting, and is 
ples  having  similar  classes,  limited  dependences,  or  limited        the bugbear of machine learning.  When your learner outputs 
complexity—are often enough to do very well, and this is a                 a  classiﬁer  that  is  100%  accurate  on  the  training  data  but 
large  part  of  why  machine  learning  has  been  so  successful.        only 50% accurate on test data,  when in fact it could have 
Like deduction, induction (what learners do) is a knowledge                output one that is 75% accurate on both, it has overﬁt. 
lever:  it  turns  a  small  amount  of  input  knowledge  into  a 
large  amount  of  output  knowledge.       Induction  is  a  vastly       Everyone  in  machine learning  knows about overﬁtting,  but 
more powerful lever than deduction, requiring much less in-                it  comes  in  many  forms  that  are  not  immediately  obvious. 
put  knowledge  to  produce  useful  results,  but  it  still  needs       One way to understand overﬁtting is by decomposing gener- 
more than zero input knowledge to work.  And, as with any                  alization error into  bias and  variance  [9].  Bias is a learner’s 
lever, the more we put in, the more we can get out.                        tendency to consistently learn the same wrong thing.  Vari- 
                                                                           ance is the tendency to learn random things irrespective of 
A corollary of this is that one of the key criteria for choos-             the real signal.  Figure 1 illustrates this by an analogy with 
ing  a  representation  is  which  kinds  of  knowledge  are  easily       throwing  darts  at  a  board.  A  linear  learner  has  high  bias, 
expressed in it.   For example, if we have a lot of knowledge              because when the frontier between two classes is not a hyper- 
about what makes examples similar in our domain, instance-                 plane the learner is unable to induce it.  Decision trees don’t 
based  methods  may  be  a  good  choice.      If  we  have  knowl-        have  this  problem  because  they  can  represent  any  Boolean 
edge about probabilistic dependencies, graphical models are                function,  but  on  the  other  hand  they  can  suﬀer  from  high 
a  good  ﬁt. And  if  we  have  knowledge  about  what  kinds  of          variance:   decision  trees  learned  on  diﬀerent   training  sets 
preconditions are required by each class, “IF  . . . THEN  . . .”          generated by the same phenomenon are often very diﬀerent, 
rules may be the the best option.  The most useful learners                when  in  fact  they  should  be  the  same.    Similar  reasoning 
in  this  regard  are  those  that  don’t  just  have  assumptions         applies  to  the  choice  of  optimization method:    beam  search 
hard-wired into them, but allow us to state them explicitly,               has lower bias than greedy search, but higher variance, be- 
vary them widely, and incorporate them automatically into                  cause it tries more hypotheses.  Thus, contrary to intuition, 
the  learning  (e.g.,  using  ﬁrst-order  logic  [22]  or  grammars        a more powerful learner is not necessarily better than a less 
[6]).                                                                      powerful one. 

In retrospect, the need for knowledge in learning should not               Figure  2  illustrates  this.1 Even  though  the  true  classiﬁer 

be  surprising.   Machine  learning  is  not  magic;  it  can’t  get       is  a  set  of  rules,  with  up  to  1000  examples  naive  Bayes  is 
something  from  nothing.      What  it  does  is  get  more  from         more  accurate  than  a  rule  learner.    This  happens  despite 
less.  Programming,      like  all  engineering, is  a  lot  of  work:     naive  Bayes’s  false  assumption  that  the  frontier  is  linear! 
we have to build everything from scratch.  Learning is more                Situations like this are common in machine learning:  strong 
like farming, which lets nature do most of the work.  Farm-                false assumptions can be better than weak true ones, because 
ers  combine  seeds  with  nutrients  to  grow  crops.    Learners         a learner with the latter needs more data to avoid overﬁtting. 
combine knowledge with data to grow programs. 

5.    OVERFITTING HAS MANY FACES                                           1Training   examples    consist  of 64  Boolean    features  and  a 
                                                                           Boolean class computed from them according to a set of “IF 
What  if  the  knowledge  and  data  we  have  are  not  suﬃcient 
                                                                           . . . THEN . . .” rules.  The curves are the average of 100 runs 
to completely determine the correct classiﬁer?  Then we run                with diﬀerent randomly generated sets of rules.         Error bars 
the risk of just hallucinating a classiﬁer (or parts of it) that           are two standard deviations.  See Domingos and Pazzani [11] 
is  not  grounded  in  reality,  and  is  simply  encoding  random         for details. 

----------------------- Page 4-----------------------

Cross-validation can help to combat overﬁtting, for example 
                                                                                   80 
by using it to choose the best size of decision tree to learn.                             Bayes 
But  it’s  no  panacea,  since  if  we  use  it  to  make  too  many          )             C4.5 
                                                                                   75 
parameter choices it can itself start to overﬁt [18].                         % 
                                                                              ( 
                                                                                  
                                                                              y 
                                                                              c    70 
Besides cross-validation, there are many methods to combat                    a 
                                                                              r 
overﬁtting.    The  most  popular  one  is  adding  a    regulariza-          u 
                                                                              c 
                                                                              c    65 
tion  term to  the  evaluation  function.    This  can,  for  exam-           A 
                                                                                  
ple, penalize classiﬁers with more structure, thereby favoring                t 
                                                                              e    60 
smaller ones with less room to overﬁt.  Another option is to                  S- 
                                                                              t 
perform  a  statistical  signiﬁcance  test  like  chi-square  before          s 
                                                                              e 
adding new structure, to decide whether the distribution of                   T    55 
the class really is diﬀerent with and without this structure. 
These  techniques  are  particularly  useful  when  data  is  very                 50 
                                                                                      10              100              1000            10000 
scarce.  Nevertheless, you should be skeptical of claims that 
a particular technique “solves” the overﬁtting problem.          It’s                               Number of Examples 
easy  to  avoid  overﬁtting  (variance)  by  falling  into  the  op- 
posite error of underﬁtting (bias).     Simultaneously avoiding            Figure    2:   Naive    Bayes    can   outperform      a  state-of- 
both requires learning a perfect classiﬁer, and short of know-             the-art  rule  learner  (C4.5rules)  even  when  the  true 
ing it in advance there is no single technique that will always            classiﬁer  is  a  set  of  rules. 
do best (no free lunch). 

A common misconception about overﬁtting is that it is caused               trillion examples,  the latter covers only a fraction of about 
by noise, like training examples labeled with the wrong class.             10−18 of the input space.  This is what makes machine learn- 

This can indeed aggravate overﬁtting, by making the learner                ing both necessary and hard. 

draw  a  capricious  frontier  to  keep  those  examples  on  what 
it  thinks  is  the  right  side. But  severe  overﬁtting  can  occur      More seriously, the similarity-based reasoning that machine 
even in the absence of noise.  For instance, suppose we learn a            learning algorithms depend on (explicitly or implicitly) breaks 
Boolean classiﬁer that is just the disjunction of the examples             down in high dimensions.  Consider a nearest neighbor clas- 
labeled “true” in the training set.  (In other words, the classi-          siﬁer with Hamming distance as the similarity measure, and 
ﬁer is a Boolean formula in disjunctive normal form, where                 suppose the  class is  just x1 ∧ x2.    If there  are  no  other fea- 
each  term  is  the  conjunction  of  the  feature  values  of  one        tures,  this  is  an  easy  problem.  But  if  there  are  98  irrele- 
speciﬁc training example).  This classiﬁer gets all the train-             vant  features  x3, . . . , x100,  the  noise  from  them  completely 
ing  examples  right  and  every  positive  test  example  wrong,          swamps the signal in x1 and x2, and nearest neighbor eﬀec- 
regardless of whether the training data is noisy or not.                   tively makes random predictions. 

The problem of multiple testing [14] is closely related to over-           Even  more  disturbing  is  that  nearest  neighbor  still  has  a 
ﬁtting.  Standard statistical tests assume that only one hy-               problem even if all 100 features are relevant!  This is because 
pothesis is being tested, but modern learners can easily test              in  high  dimensions  all  examples  look  alike.     Suppose,   for 
millions before they are done.  As a result what looks signif-             instance,  that  examples  are  laid  out  on  a  regular  grid,  and 
                                                                           consider a test example x  .  If the grid is d-dimensional, x  ’s 
icant may in fact not be.     For example, a mutual fund that                                           t                                    t 
beats  the  market  ten  years  in  a  row  looks  very  impressive,       2d  nearest  examples  are  all  at  the  same  distance  from  it. 
until you realize that,  if there are 1000 funds and each has              So as the dimensionality increases, more and more examples 
                                                                           become  nearest  neighbors of  x  ,  until  the  choice  of  nearest 
a 50% chance of beating the market on any given year, it’s                                                     t 
quite likely that one will succeed all ten times just by luck.             neighbor (and therefore of class) is eﬀectively random. 

This  problem  can  be  combatted  by  correcting  the  signiﬁ- 
cance tests to take the number of hypotheses into account,                 This  is  only  one  instance  of  a  more  general  problem  with 
but  this  can  lead  to  underﬁtting.   A  better  approach  is  to       high  dimensions:    our  intuitions,  which  come  from  a  three- 
control the fraction of falsely accepted non-null hypotheses,              dimensional  world,  often  do  not  apply  in  high-dimensional 
known as the false discovery rate  [3].                                    ones.  In  high  dimensions,  most  of  the  mass  of  a  multivari- 
                                                                           ate  Gaussian  distribution  is  not  near  the  mean,  but  in  an 
6.    INTUITION FAILS IN HIGH                                              increasingly  distant “shell” around  it;  and  most  of  the  vol- 
                                                                           ume of a high-dimensional orange is in the skin, not the pulp. 
      DIMENSIONS 
                                                                           If a constant number of examples is distributed uniformly in 
After  overﬁtting,  the  biggest  problem  in  machine  learning           a high-dimensional hypercube, beyond some dimensionality 
is  the  curse  of  dimensionality.  This  expression  was  coined         most  examples  are  closer  to  a  face  of  the  hypercube  than 
by  Bellman  in   1961  to   refer to  the  fact  that  many  algo-        to  their  nearest  neighbor.  And  if  we  approximate a  hyper- 
rithms that work ﬁne in low dimensions become intractable                  sphere  by  inscribing  it  in  a  hypercube,  in  high  dimensions 
when the input is high-dimensional.        But in machine learn-           almost all the volume of the hypercube is outside the hyper- 
ing it refers to much more.      Generalizing correctly becomes            sphere.  This is bad news for machine learning, where shapes 
exponentially harder  as  the  dimensionality (number  of  fea-            of one type are often approximated by shapes of another. 
tures)  of  the  examples  grows,  because  a  ﬁxed-size  training 
set covers a dwindling fraction of the input space.  Even with             Building  a  classiﬁer  in  two  or  three  dimensions  is  easy;  we 
a  moderate  dimension  of  100  and  a  huge  training  set  of  a 

----------------------- Page 5-----------------------

                                                                                                                       d 
can ﬁnd a reasonable frontier between examples of diﬀerent                      total  number  of  functions  is  22  .    And  even  for  hypothesis 

classes just by visual inspection.  (It’s even been said that if                 spaces that are “merely” exponential, the bound is still very 
people could see in high dimensions machine learning would                       loose, because the union bound is very pessimistic.             For ex- 
not be necessary.)  But in high dimensions it’s hard to under-                   ample, if there are 100 Boolean features and the hypothesis 
stand what is happening.         This in turn makes it diﬃcult to                space  is  decision  trees  with  up  to  10  levels,    to  guarantee 
design a good classiﬁer.  Naively, one might think that gath-                    δ  = ǫ = 1%  in  the  bound  above  we  need  half  a  million  ex- 
ering more features never hurts, since at worst they provide                     amples.   But  in  practice  a  small  fraction  of  this  suﬃces  for 
no new information about the class.  But in fact their bene-                     accurate learning. 
ﬁts may be outweighed by the curse of dimensionality. 
                                                                                 Further, we have to be careful about what a bound like this 
Fortunately,  there  is  an  eﬀect  that  partly  counteracts  the               means.    For  instance,  it  does  not  say  that,  if  your  learner 
curse, which might be called the“blessing of non-uniformity.”                   returned  a  hypothesis  consistent  with  a  particular  training 
In most applications examples are not spread uniformly thr-                      set,  then  this  hypothesis  probably  generalizes  well.        What 
oughout the instance space, but are concentrated on or near                      it says is that, given a large enough training set, with high 
a lower-dimensional manifold.  For example, k-nearest neigh-                    probability your learner will either return a hypothesis that 
bor works quite well for handwritten digit recognition even                     generalizes well or be unable to ﬁnd a consistent hypothesis. 
though  images  of  digits  have  one  dimension  per  pixel,  be-               The bound also says nothing about how to select a good hy- 
cause  the  space  of  digit  images  is  much  smaller  than  the              pothesis space.  It only tells us that, if the hypothesis space 
space  of  all  possible  images.     Learners  can  implicitly  take            contains  the  true  classiﬁer,    then  the  probability  that  the 
advantage  of  this  lower  eﬀective  dimension,  or  algorithms                 learner  outputs  a  bad  classiﬁer  decreases  with  training  set 
for explicitly reducing the dimensionality can be used (e.g.,                    size.  If we shrink the hypothesis space, the bound improves, 
[23]).                                                                          but  the  chances  that  it  contains  the  true  classiﬁer  shrink 
                                                                                 also.  (There  are  bounds for  the  case  where  the  true  classi- 
                                                                                ﬁer is not in the hypothesis space, but similar considerations 
7.    THEORETICAL GUARANTEES ARE                                                 apply to them.) 
      NOT WHAT THEY SEEM 
                                                                                 Another  common  type  of  theoretical  guarantee  is  asymp- 
Machine  learning  papers  are  full  of  theoretical  guarantees. 
                                                                                totic:  given inﬁnite data, the learner is guaranteed to output 
The  most  common  type  is  a  bound  on  the  number  of  ex- 
                                                                                the correct classiﬁer.  This is reassuring, but it would be rash 
amples needed to ensure good generalization.  What should 
                                                                                to choose one learner over another because of its asymptotic 
you  make  of  these  guarantees?       First  of  all,  it’s  remarkable 
                                                                                guarantees.      In  practice,  we  are  seldom  in  the  asymptotic 
that they  are  even  possible.     Induction is  traditionally con- 
                                                                                regime  (also  known  as “asymptopia”).          And,  because  of  the 
trasted with deduction:  in deduction you can guarantee that 
                                                                                bias-variance tradeoﬀ we discussed above, if learner A is bet- 
the conclusions are correct; in induction all bets are oﬀ.  Or 
                                                                                ter than learner B given inﬁnite data, B is often better than 
such was the conventional wisdom for many centuries.  One 
                                                                                 A given ﬁnite data. 
of  the  major  developments  of  recent  decades  has  been  the 
realization  that  in  fact  we  can  have  guarantees  on  the  re- 
                                                                                 The main role of theoretical guarantees in machine learning 
sults  of  induction,  particularly  if  we’re  willing  to  settle  for 
                                                                                 is not as a criterion for practical decisions, but as a source of 
probabilistic guarantees. 
                                                                                 understanding and driving force for algorithm design.  In this 
                                                                                 capacity,  they  are  quite  useful;  indeed,  the  close  interplay 
The  basic  argument  is  remarkably  simple  [5].         Let’s  say  a 
                                                                                of  theory  and  practice  is  one  of  the  main  reasons  machine 
classiﬁer is bad if its true error rate is greater than ǫ.  Then 
                                                                                 learning  has  made  so  much  progress  over  the  years.          But 
the probability that a bad classiﬁer is consistent with n ran- 
                                                                       n         caveat emptor:  learning is a complex phenomenon, and just 
dom,  independent  training  examples  is  less  than  (1 − ǫ)          . 
                                                                                because a learner has a theoretical justiﬁcation and works in 
Let  b  be  the  number  of  bad  classiﬁers  in  the  learner’s  hy- 
                                                                                practice doesn’t mean the former is the reason for the latter. 
pothesis space H .  The probability that at least one of them 
is consistent    is less  than   b(1 − ǫ)n ,   by  the   union   bound. 

Assuming the learner always returns a  consistent classiﬁer,                     8.    FEATURE ENGINEERING IS THE KEY 
the  probability  that  this  classiﬁer  is  bad  is  then  less  than           At the end of the day, some machine learning projects suc- 
|H |(1 − ǫ)n ,  where  we  have  used  the  fact  that b  ≤ |H |.     So         ceed  and   some    fail.  What    makes    the   diﬀerence?     Easily 

if  we  want  this  probability  to  be  less  than  δ ,  it  suﬃces  to        the most important factor is the features used.             If you have 
make n > ln(δ/|H |)/ ln(1 − ǫ) ≥ 1  ln |H |+ ln 1.                              many independent features that each correlate well with the 

                                         ǫ                δ 
                                                                                 class,  learning  is  easy.   On  the  other  hand,  if  the  class  is 
Unfortunately, guarantees of this type have to be taken with                     a  very  complex  function  of  the  features,      you  may  not  be 
a large grain of salt.  This is because the bounds obtained in                   able to learn it.  Often, the raw data is not in a form that is 
this way are usually extremely loose.  The wonderful feature                     amenable to learning, but you can construct features from it 
of the bound above is that the required number of examples                      that are.  This is typically where most of the eﬀort in a ma- 
only grows logarithmically with |H | and 1/δ.  Unfortunately,                    chine learning project goes.  It is often also one of the most 
most interesting hypothesis spaces are doubly exponential in                     interesting parts, where intuition, creativity and “black art” 
the number of features d, which still leaves us needing a num-                   are as important as the technical stuﬀ. 
ber of examples exponential in d.  For example, consider the 
space  of  Boolean  functions of  d  Boolean  variables.        If  there        First-timers are often surprised by how little time in a ma- 
are  e  possible  diﬀerent  examples,  there  are  2e     possible  dif-         chine learning project is spent actually doing machine learn- 
ferent functions, so since there are 2d  possible examples, the                  ing.  But it makes sense if you consider how time-consuming 

----------------------- Page 6-----------------------

it is to gather data, integrate it, clean it and pre-process it,                    N. Bayes 
and  how  much  trial  and  error  can  go  into  feature  design. 
Also,  machine  learning  is  not  a  one-shot  process  of  build-                                           kNN 
ing a data set and running a learner, but rather an iterative                        SVM 
process of running the learner, analyzing the results, modi- 
fying the data and/or the learner, and repeating.           Learning 
is  often  the  quickest  part  of  this,  but  that’s  because  we’ve 
already mastered it pretty well!  Feature engineering is more 
diﬃcult  because  it’s  domain-speciﬁc,  while  learners  can  be 
largely general-purpose.  However, there is no sharp frontier 
between the two, and this is another reason the most useful 
learners are those that facilitate incorporating knowledge.                                                        D. Tree 

Of  course,  one  of  the  holy  grails  of  machine  learning  is  to 
automate more and more of the feature engineering process. 
One  way  this  is  often  done  today  is  by  automatically  gen-          Figure  3:    Very  diﬀerent  frontiers  can  yield  similar 
erating  large  numbers  of  candidate  features  and  selecting             class predictions.      (+ and  − are training examples of 
the best by (say) their information gain with respect to the                 two  classes.) 
class.  But  bear  in  mind  that  features  that  look  irrelevant 
in  isolation  may  be  relevant  in  combination.     For  example,         and  neural  networks.      But  in  fact  propositional  rules  are 
if the class is an XOR of  k  input features, each of them by                readily  encoded    as  neural  networks,    and   similar  relation- 
itself  carries  no  information  about  the  class.   (If  you  want        ships  hold  between  other  representations.       All  learners  es- 
to  annoy  machine  learners,  bring  up  XOR.)  On  the  other              sentially  work  by  grouping  nearby  examples  into  the  same 
hand,  running  a  learner  with  a  very  large  number  of  fea-           class; the key diﬀerence is in the meaning of “nearby.” With 
tures to ﬁnd out which ones are useful in combination may                    non-uniformly distributed data, learners can produce widely 
be too time-consuming, or cause overﬁtting.  So there is ul-                 diﬀerent frontiers while still making the same predictions in 
timately no replacement for the smarts you put into feature                  the regions that matter (those with a substantial number of 
engineering.                                                                 training  examples,  and  therefore  also  where  most  test  ex- 

                                                                             amples  are  likely  to  appear).   This  also  helps  explain  why 
9.    MORE DATA BEATS A CLEVERER                                             powerful  learners  can  be  unstable  but  still  accurate.     Fig- 
      ALGORITHM                                                              ure  3  illustrates  this  in  2-D;  the  eﬀect  is  much  stronger  in 
Suppose    you’ve   constructed    the  best   set  of features   you        high dimensions. 
can,  but  the  classiﬁers  you’re  getting  are  still  not  accurate 
enough.  What can you do now?  There are two main choices:                   As a rule, it pays to try the simplest learners ﬁrst (e.g., naive 
design   a  better  learning   algorithm,    or  gather  more    data        Bayes  before  logistic  regression,  k-nearest  neighbor  before 
(more examples, and possibly more raw features, subject to                   support  vector  machines).      More  sophisticated  learners  are 
the  curse  of  dimensionality).    Machine  learning  researchers           seductive, but they are usually harder to use, because they 
are  mainly  concerned  with  the  former,       but  pragmatically          have more knobs you need to turn to get good results, and 
the quickest path to success is often to just get more data.                 because their internals are more opaque. 
As a rule of thumb, a dumb algorithm with lots and lots of 
data  beats  a  clever  one  with  modest  amounts  of  it.    (After        Learners can be divided into two major types:  those whose 
all, machine learning is all about letting data do the heavy                 representation  has    a  ﬁxed  size,  like linear  classiﬁers,  and 
lifting.)                                                                    those whose representation can grow with the data, like deci- 
                                                                             sion trees.  (The latter are sometimes called non-parametric 
This  does  bring  up  another  problem,  however:        scalability.       learners, but this is somewhat unfortunate, since they usu- 
In most of computer science, the two main limited resources                  ally wind up learning many more parameters than paramet- 
are time and memory.  In machine learning, there is a third                  ric ones.)  Fixed-size learners can only take advantage of so 
one:  training data.  Which one is the bottleneck has changed                much data.  (Notice how the accuracy of naive Bayes asymp- 
from decade to decade.       In the 1980’s it tended to be data.             totes at around 70% in Figure 2.)  Variable-size learners can 
Today  it  is  often  time.   Enormous  mountains  of  data  are             in  principle  learn  any  function  given  suﬃcient  data,  but  in 
available,  but  there  is  not  enough  time  to  process  it,  so  it      practice  they  may  not,  because  of  limitations  of  the  algo- 
goes unused.  This leads to a paradox:  even though in prin-                 rithm (e.g., greedy search falls into local optima) or compu- 
ciple more data means that more complex classiﬁers can be                    tational  cost.  Also,  because  of  the  curse  of  dimensionality, 
learned,  in  practice  simpler  classiﬁers  wind  up  being  used,          no  existing  amount  of  data  may  be  enough.     For  these  rea- 
because  complex  ones  take  too  long  to  learn.      Part  of  the       sons,  clever  algorithms—those  that  make  the  most  of  the 
answer is to come up with fast ways to learn complex classi-                 data  and  computing  resources  available—often  pay  oﬀ  in 
ﬁers, and indeed there has been remarkable progress in this                  the end, provided you’re willing to put in the eﬀort.          There 
direction (e.g., [12]).                                                      is  no  sharp  frontier  between  designing  learners  and  learn- 
                                                                             ing classiﬁers; rather, any given piece of knowledge could be 
Part  of  the  reason  using  cleverer  algorithms  has  a  smaller          encoded  in  the  learner  or  learned  from  data.     So  machine 
payoﬀ than you might expect is that, to a ﬁrst approxima-                    learning projects often wind up having a signiﬁcant compo- 
tion,  they  all do   the  same.    This  is surprising  when     you        nent of learner design, and practitioners need to have some 
consider   representations    as  diﬀerent   as, say,  sets  of rules        expertise in it [13]. 

----------------------- Page 7-----------------------

In the end, the biggest bottleneck is not data or CPU cycles,             those produced by (say) bagging or boosting:  the latter are 
but human cycles.  In research papers, learners are typically             fairly  even,  while  the  former  are  extremely  skewed,  to  the 
compared on measures of accuracy and computational cost.                  point where the single highest-weight classiﬁer usually dom- 
But human eﬀort saved and insight gained, although harder                 inates,  making BMA eﬀectively equivalent to just selecting 
to  measure,  are  often  more  important.     This  favors  learn-       it  [8]. A  practical  consequence  of  this  is  that,  while  model 
ers  that  produce  human-understandable  output  (e.g.,  rule            ensembles  are  a  key  part  of  the  machine  learning  toolkit, 
sets).  And  the  organizations  that  make  the  most  of  ma-           BMA is seldom worth the trouble. 
chine learning are those that have in place an infrastructure 
that makes experimenting with many diﬀerent learners, data 
sources and learning problems easy and eﬃcient, and where 
there is a close collaboration between machine learning ex- 
perts and application domain ones.                                        11.    SIMPLICITY DOES NOT IMPLY 
                                                                                 ACCURACY 
10.     LEARN MANY MODELS, NOT JUST                                       Occam’s  razor  famously  states  that  entities  should  not  be 
        ONE                                                               multiplied beyond necessity.  In machine learning, this is of- 
In the early days of machine learning, everyone had their fa-             ten taken to mean that, given two classiﬁers with the same 
vorite learner, together with some a priori reasons to believe            training  error,  the  simpler  of  the  two  will  likely  have  the 
in its superiority.  Most eﬀort went into trying many varia-              lowest test error.  Purported proofs of this claim appear reg- 
tions of it and selecting the best one.  Then systematic em-              ularly in the literature, but in fact there are many counter- 
pirical comparisons showed that the best learner varies from              examples  to  it,  and  the “no  free  lunch” theorems  imply  it 
application to application, and systems containing many dif-              cannot be true. 
ferent learners started to appear.  Eﬀort now went into try- 
ing many variations of many learners, and still selecting just            We saw one counter-example in the previous section:  model 
the  best  one. But  then  researchers  noticed  that,  if  instead       ensembles.    The  generalization  error  of  a  boosted  ensem- 
of selecting the best variation found, we combine many vari-              ble continues to improve by adding classiﬁers even after the 
ations,  the  results  are  better—often  much  better—and  at            training error has reached zero.  Another counter-example is 
little extra eﬀort for the user.                                          support vector machines, which can eﬀectively have an inﬁ- 
                                                                          nite number of parameters without overﬁtting.         Conversely, 
Creating  such  model  ensembles is  now  standard  [1].    In  the       the  function  sign(sin(ax))   can  discriminate   an  arbitrarily 
simplest technique,  called  bagging,  we simply generate ran-            large,  arbitrarily  labeled  set  of  points  on  the  x  axis,  even 
dom  variations  of  the  training  set  by  resampling,   learn  a       though it has only one parameter [24].  Thus, contrary to in- 
classiﬁer  on  each,  and  combine  the  results  by  voting. This        tuition, there is no necessary connection between the number 
works because it greatly reduces variance while only slightly             of parameters of a model and its tendency to overﬁt. 
increasing bias.  In boosting, training examples have weights, 
and  these  are  varied  so  that  each  new  classiﬁer  focuses  on      A more sophisticated view instead equates complexity with 
the  examples  the  previous  ones  tended  to  get  wrong.      In       the  size  of  the  hypothesis  space,  on  the  basis  that  smaller 
stacking, the outputs of individual classiﬁers become the in-             spaces allow hypotheses to be represented by shorter codes. 
puts of a “higher-level” learner that ﬁgures out how best to              Bounds like the one in the section on theoretical guarantees 
combine them.                                                             above  might  then  be  viewed  as  implying  that  shorter  hy- 
                                                                          potheses  generalize  better.   This  can  be  further  reﬁned  by 
Many other techniques exist, and the trend is toward larger               assigning shorter  codes  to  the  hypothesis in  the  space  that 
and  larger  ensembles.   In  the  Netﬂix  prize,  teams  from  all       we  have  some   a  priori preference  for. But  viewing  this  as 
over  the  world  competed     to build  the  best  video  recom-         “proof” of a tradeoﬀ between accuracy and simplicity is cir- 
mender  system  (http://netﬂixprize.com).        As  the  competi-        cular reasoning:  we made the hypotheses we prefer simpler 
tion  progressed,  teams  found  that  they  obtained  the  best          by  design,  and  if  they  are  accurate  it’s  because  our  prefer- 
results  by  combining  their  learners  with  other  teams’,  and        ences are accurate, not because the hypotheses are “simple” 
merged into larger and larger teams.  The winner and runner-              in the representation we chose. 
up  were  both  stacked  ensembles  of  over  100  learners,  and 
combining  the  two  ensembles  further  improved  the  results.          A further complication arises from the fact that few learners 
Doubtless we will see even larger ones in the future.                     search their hypothesis space exhaustively.  A learner with a 
                                                                          larger  hypothesis  space  that  tries  fewer  hypotheses  from  it 
Model ensembles should not be confused with Bayesian model                is  less  likely  to  overﬁt  than  one  that  tries  more  hypotheses 
averaging (BMA). BMA is the theoretically optimal approach                from  a  smaller  space.  As  Pearl  [19]  points  out,  the  size  of 
to  learning  [4]. In  BMA,  predictions  on  new  examples  are          the  hypothesis  space  is  only  a  rough  guide  to  what  really 
made by averaging the individual predictions of all classiﬁers            matters  for  relating  training  and  test  error: the  procedure 
in the hypothesis space, weighted by how well the classiﬁers              by which a hypothesis is chosen. 
explain the training data and how much we believe in them 
a priori.  Despite their superﬁcial similarities, ensembles and           Domingos [7]  surveys the main  arguments and evidence on 
BMA  are  very  diﬀerent.    Ensembles  change  the  hypothesis           the issue of Occam’s razor in machine learning.  The conclu- 
space (e.g., from single decision trees to linear combinations            sion is that simpler hypotheses should be preferred because 
of them), and can take a wide variety of forms.  BMA assigns              simplicity  is  a  virtue  in  its  own  right,  not  because  of  a  hy- 
weights to the hypotheses in the original space according to              pothetical connection with accuracy.  This is probably what 
a ﬁxed formula.  BMA weights are extremely diﬀerent from                  Occam meant in the ﬁrst place. 

----------------------- Page 8-----------------------

12.     REPRESENTABLE DOES NOT IMPLY                                        Many researchers believe that causality is only a convenient 
        LEARNABLE                                                           ﬁction.  For example, there is no notion of causality in phys- 
Essentially all representations used in variable-size learners              ical  laws. Whether  or  not  causality  really  exists  is  a  deep 
have  associated  theorems  of  the  form “Every  function  can             philosophical   question   with   no  deﬁnitive   answer   in sight, 
                                                                            but the practical points for machine learners are two.  First, 
be  represented,   or  approximated  arbitrarily  closely,     using 
this  representation.”   Reassured  by  this,  fans  of  the  repre-        whether or not we call them “causal,” we would like to pre- 
sentation  often  proceed  to  ignore  all  others.  However,  just         dict the eﬀects of our actions, not just correlations between 
because a function can be represented does not mean it can                  observable variables.  Second, if you can obtain experimental 
be  learned.    For  example,   standard  decision  tree  learners          data (for example by randomly assigning visitors to diﬀerent 
cannot learn trees with more leaves than there are training                 versions of a Web site), then by all means do so [15]. 

examples.    In  continuous  spaces,  representing  even  simple 
functions  using  a  ﬁxed  set  of  primitives  often  requires  an         14.     CONCLUSION 
inﬁnite  number  of  components.       Further,  if  the  hypothesis        Like any discipline, machine learning has a lot of “folk wis- 
space has many local optima of the evaluation function,  as                 dom” that  can  be  hard  to  come  by,  but  is  crucial  for  suc- 
is often the case, the learner may not ﬁnd the true function                cess.  This article summarized some of the most salient items. 
even if it is representable.  Given ﬁnite data, time and mem-               A  good  place  to  learn  more  is  my  book   The  Master  Algo- 
ory, standard learners can learn only a tiny subset of all pos-             rithm, a non-technical introduction to machine learning [10]. 
sible  functions,  and  these  subsets  are  diﬀerent  for  learners        For  a  complete  online  machine  learning  course,  check  out 
with diﬀerent representations.  Therefore the key question is               http://www.cs.washington.edu/homes/pedrod/class.  There 
not “Can  it  be  represented?”,  to  which  the  answer  is  often         is also a treasure trove of machine learning lectures at http:- 
trivial, but “Can it be learned?” And it pays to try diﬀerent               //www.videolectures.net.       A  widely  used  open  source  ma- 
learners (and possibly combine them).                                       chine learning toolkit is Weka [25].  Happy learning! 

Some representations are exponentially more compact than                    15.     REFERENCES 
others  for  some  functions.    As  a  result,  they  may  also  re-        [1]  E. Bauer and R. Kohavi. An empirical comparison of 
quire exponentially less data to learn those functions.  Many                    voting classiﬁcation algorithms:  Bagging, boosting 
learners work by forming linear combinations of simple ba-                       and variants. Machine Learning, 36:105–142, 1999. 
sis  functions.  For  example,  support  vector  machines  form              [2]  Y. Bengio. Learning deep architectures for AI. 
combinations of kernels centered at some of the training ex-                     Foundations and Trends in Machine Learning, 
amples (the support vectors).  Representing parity of n bits                     2:1–127, 2009. 
in  this  way  requires  2n basis  functions.  But  using  a  repre-         [3]  Y. Benjamini and Y. Hochberg. Controlling the false 

sentation  with  more  layers  (i.e.,  more  steps  between  input               discovery rate:  A practical and powerful approach to 
and output), parity can be encoded in a linear-size classiﬁer.                   multiple testing.  Journal of the Royal Statistical 
Finding methods to learn these deeper representations is one                     Society, Series B, 57:289–300, 1995. 
of the major research frontiers in machine learning [2].                     [4]  J. M. Bernardo and A. F. M. Smith. Bayesian Theory. 

                                                                                 Wiley, New York, NY, 1994. 
                                                                             [5]  A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. 
13.     CORRELATION DOES NOT IMPLY                                               Warmuth. Occam’s razor.  Information Processing 
                                                                                 Letters, 24:377–380, 1987. 
        CAUSATION 
                                                                             [6]  W. W. Cohen. Grammatically biased learning: 
The point that correlation does not imply causation is made 
                                                                                 Learning logic programs using an explicit antecedent 
so often that it is perhaps not worth belaboring.  But, even 
                                                                                 description language. Artiﬁcial Intelligence, 
though learners of the kind we have been discussing can only 
                                                                                 68:303–366, 1994. 
learn  correlations,  their  results  are  often  treated  as  repre- 
                                                                             [7]  P. Domingos. The role of Occam’s razor in knowledge 
senting  causal  relations.   Isn’t  this  wrong?  If  so,  then  why 
                                                                                 discovery. Data Mining and Knowledge Discovery, 
do people do it? 
                                                                                 3:409–425, 1999. 
More  often  than  not,  the  goal  of  learning  predictive  mod-           [8]  P. Domingos. Bayesian averaging of classiﬁers and the 
els  is  to  use  them  as  guides  to  action. If  we  ﬁnd  that  beer          overﬁtting problem. In  Proceedings of the Seventeenth 
and  diapers  are  often  bought  together  at  the  supermarket,                International Conference on Machine Learning, pages 
then  perhaps  putting  beer  next  to  the  diaper  section  will               223–230, Stanford, CA, 2000. Morgan Kaufmann. 
increase  sales.  (This  is  a  famous  example  in  the  world  of          [9]  P. Domingos. A uniﬁed bias-variance decomposition 
data  mining.)    But  short  of  actually  doing  the  experiment               and its applications. In Proceedings of the Seventeenth 
it’s  diﬃcult  to  tell. Machine  learning  is  usually  applied  to             International Conference on Machine Learning, pages 
observational  data,  where  the  predictive  variables  are  not                231–238, Stanford, CA, 2000. Morgan Kaufmann. 
under the control of the learner, as opposed to  experimental               [10]  P. Domingos.  The Master Algorithm:  How the Quest 
data, where they are.  Some learning algorithms can poten-                       for the Ultimate Learning Machine Will Remake Our 
tially  extract  causal  information  from  observational  data,                  World. Basic Books, New York, NY, 2015. 
but their applicability is rather restricted [20].  On the other            [11]  P. Domingos and M. Pazzani. On the optimality of the 
hand, correlation is a sign of a potential causal connection,                    simple Bayesian classiﬁer under zero-one loss. Machine 
and  we  can  use  it  as  a  guide  to  further  investigation  (for            Learning, 29:103–130, 1997. 
example, trying to understand what the causal chain might                   [12]  G. Hulten and P. Domingos. Mining complex models 
be).                                                                             from arbitrarily large databases in constant time. In 

----------------------- Page 9-----------------------

     Proceedings of the Eighth ACM SIGKDD International 
     Conference on Knowledge Discovery and Data Mining, 
     pages 525–531, Edmonton, Canada, 2002. ACM Press. 
[13]  D. Kibler and P. Langley. Machine learning as an 
     experimental science. In  Proceedings of the Third 
     European Working Session on Learning, London, UK, 
     1988. Pitman. 
[14]  A. J. Klockars and G. Sax. Multiple Comparisons. 
     Sage, Beverly Hills, CA, 1986. 
[15]  R. Kohavi, R. Longbotham, D. Sommerﬁeld, and 
     R. Henne. Controlled experiments on the Web:  Survey 
     and practical guide. Data Mining and Knowledge 
     Discovery, 18:140–181, 2009. 
[16]  J. Manyika, M. Chui, B. Brown, J. Bughin, R. Dobbs, 
     C. Roxburgh, and A. Byers. Big data:  The next 
     frontier for innovation, competition, and productivity. 
     Technical report, McKinsey Global Institute, 2011. 
[17]  T. M. Mitchell. Machine Learning. McGraw-Hill, New 
     York, NY, 1997. 
[18]  A. Y. Ng. Preventing “overﬁtting” of cross-validation 
     data. In Proceedings of the Fourteenth International 
     Conference on Machine Learning, pages 245–253, 
     Nashville, TN, 1997. Morgan Kaufmann. 
[19]  J. Pearl. On the connection between the complexity 
     and credibility of inferred models. International 
     Journal of General Systems, 4:255–264, 1978. 
[20]  J. Pearl. Causality:  Models, Reasoning, and Inference. 
     Cambridge University Press, Cambridge, UK, 2000. 
[21]  J. R. Quinlan. C4.5:  Programs for Machine Learning. 
     Morgan Kaufmann, San Mateo, CA, 1993. 
[22]  M. Richardson and P. Domingos. Markov logic 
     networks. Machine Learning, 62:107–136, 2006. 
[23]  J. Tenenbaum, V. Silva, and J. Langford. A global 
     geometric framework for nonlinear dimensionality 
     reduction.  Science, 290:2319–2323, 2000. 
[24]  V. N. Vapnik.  The Nature of Statistical Learning 
     Theory. Springer, New York, NY, 1995. 
[25]  I. Witten, E. Frank, and M. Hall. Data Mining: 
     Practical Machine Learning Tools and Techniques. 
     Morgan Kaufmann, San Mateo, CA, 3rd edition, 2011. 
[26]  D. Wolpert. The lack of a priori distinctions between 
     learning algorithms. Neural Computation, 
     8:1341–1390, 1996. 
